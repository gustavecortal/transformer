# Transformer
Slides from my NLP course on the transformer architecture based on *Dan Jurafsky and James H. Martin (2024). Speech and Language Processing (3rd ed. draft).*

See also:

- [N-grams](https://github.com/gustavecortal/ngram)
- [Naive bayes](https://github.com/gustavecortal/naive-bayes)
- [Feedforward neural networks](https://github.com/gustavecortal/feedforward-neural-networks)
- [Recurrent neural networks and attention mechanisms](https://github.com/gustavecortal/recurrent-neural-networks)
